# Teacher, Data Analyst/Scientist & Product Data Manager
    - See blue link to the portfolio toward the end of the resume
## Professional Profile
As a seasoned Data Scientist with extensive experience extracting valuable insights and knowledge from complex datasets, I specialise in employing advanced visualisation and statistical analysis techniques. My expertise lies in identifying and interpreting interrelationships between various features within datasets, contributing significantly to understanding and predicting target variables and features. Proficient in not only the technical aspects of data science but also in navigating the legal and ethical constraints associated with handling sensitive data; I ensure that all practices adhere to the highest standards of data ethics and compliance. This blend of technical understanding and ethical awareness positions me as a versatile and responsible professional in data science.

## Technical Skills: Python, PowerBI, Excel, TABLEAU

## Education
- #### SCQF LEVEL 9, Data Science with Python | The Robert Gordon University Aberdeen, UK (December 2023)
- #### M.Sc., HRM | The Robert Gordon University Aberdeen, UK (November 2009)
- #### MPSM., Economics, Policy & Project Management  | Ghana Institute of Management and Public Administration, Accra, Ghana (December 2006)
- #### B.Sc[ED] Hons., Economics | The Lagos State University Lagos, Nigeria (September 2002)

## Work Experience

#### Product Data Manager @ ABM Multisector Ltd (Sept 2010 - Present)
A results-oriented Product Manager with a sincere dedication to crafting user-focused products that bolster business growth. Demonstrates a proven track record in translating market insights into effective product strategies and steering agile development teams to deliver premium products punctually and within budget.

**Experience/Skills**
A results-driven Product Manager with a commitment to user-centric product development, leveraging data analytics and agile methodologies to drive business growth.
- Conduct comprehensive market research and competitor analysis, resulting in a 10% increase in market share. Using Helium 10 and Keepa data analytics tools to inform my judgement.
- Implement agile methodologies, boosting product development efficiency by 25%.
- Collaborate with stakeholders to prioritize features based on customer needs, enhancing customer retention by 10%.
- Manage product budgets and resources effectively, maximizing ROI.
- Utilize data analytics and user feedback to refine product decisions continuously.

These strategies led to successful product launches, improved usability by 15%, and fostered enduring client relationships, contributing to a 20% rise in product adoption and mitigating risks throughout the product lifecycle.
**Skills:** Data Analysis, Web Design and Development (jobruns.com) · Project Planning · Human Resources Information Systems (HRIS) · Microsoft Power BI · Agile Methodologies · Leadership · Business Strategy · Python (Programming Language) · Data Analysis


#### Teacher, Economics, Business Management, Information Technology @ Aberdeen City Council (January 2015 - Present)
**Experience/Skills**
- Technological Fluency Advancement: Demonstrates a strong track record in enhancing students’ technological fluency, which is crucial for navigating a digitalised future.
- Engaging Curriculum Development: Skilled in crafting captivating curricula that inspire dynamic learning experiences and foster student interest and participation.
- Utilisation of Modern Teaching Tools: Utilises state-of-the-art teaching tools and digital media to maximise student engagement and comprehension, ensuring effective learning outcomes.
- Comprehensive Student Progress Monitoring: Diligently tracks student progress and sets ambitious targets, providing accurate predictions for examination outcomes and guiding students toward academic success.
- Holistic Student Support and Development: A student mentor effectively communicates progress and improvement areas to students and families. Leads extracurricular activities promoting well-rounded growth while maintaining positive educational standards.

#### Business Data Analyst @ Centre for Energy Research and Development, Nigeria (January 2002 - August 2008)
Engineered, designed, and maintained advanced data warehouses and BI solutions; Transformed diverse data sources into organised formats using BI tools; Produced valuable insights and comprehensive reports for informed decisions. 

**Experience/Skills**
- Advanced Data Infrastructure Management: Spearheaded the engineering, design, and maintenance of sophisticated data warehouses and BI solutions, ensuring optimal performance and functionality.
- Data Transformation Expertise: Proficiently converted diverse data sources into structured formats using cutting-edge BI tools, facilitating streamlined analysis and decision-making processes.
- Insightful Reporting and Decision Support: I produced comprehensive reports and valuable insights, empowering stakeholders with the information needed to make informed decisions and drive business growth.
- Efficiency Enhancement: Optimised I optimised warehouse architecture and implemented advanced BI tools, resulting in a notable 32% improvement in data quality, a 21% reduction in time b, and a 48% reduction in costs	
- Data Security Assurance: We implemented and ensured strong data security measures, safeguarding sensitive information against unauthorised access or breaches.
Seamless Data Modeling: Designed models for seamless querying and analysis, enhancing the efficiency and accuracy of data-driven insights and decision-making processes.

# Projects Portfolio
### Programming Languages & Software Skills
- Proficient in SQL, Python, and similar languages; these technical skills form the backbone of my expertise. In my previous roles, I have utilised SQL for database management and Python for data analysis and automation tasks. For example, I developed a Python-based tool to automate data collection in a recent project, significantly improving efficiency.

### [Data Modelling Project](https://github.com/aadegoke74/Data-Modelling-Project)
#### - Explanation of why delay, date or port should not be used as predictors
Here are more technical reasons for the non-inclusion of variables and the selection of predictors:
    
- **'Delay':** This variable may not be a reliable predictor due to its susceptibility to confounding factors or external influences not captured in the dataset. Various unmeasured variables could influence' Delay',             making it a poor predictor of the outcome. Its inclusion without proper consideration could lead to misleading conclusions or spurious correlations.
   
- **'Date':** The 'Date' variable might introduce seasonality effects, which could complicate the modelling process and require advanced techniques to account for temporal patterns adequately. Without proper handling,           the 'Date' variable may not contribute meaningfully to the prediction task and could introduce noise or bias into the model.
   
- **'Port':** While 'Port' may provide contextual information, it may not directly influence the outcome and could lead to overfitting or biased predictions if used as a predictor without careful consideration. The                 geographical specifics represented by 'Port' may not be inherently linked to the outcome variable, making it a less informative predictor than other variables with stronger causal relationships.

By excluding these variables or treating them carefully in the modelling process, I can mitigate the risk of introducing spurious correlations and ensure that the selected predictors contribute meaningfully to the model's predictive performance.

#### - Justify the choice of the variables that are used as predictors
Selecting suitable predictors is pivotal for a model's predictive accuracy and intelligibility. Such predictors warrant theoretical or empirical grounding to affirm their relation to the dependent variable. For instance, in maritime logistics, 'TEU' and 'time' are cogent predictors for efficiency, directly quantifying cargo size and processing duration. Similarly, 'gear' could be a robust predictor given its direct operational impact. This aligns with Sharma and Ranjan's (2023) perspective on predictive modelling in intelligent systems.

In contrast, indicators like 'delay' or confounders like 'date', which may obscure underlying seasonal influences, demand a cautious approach. While providing locational context, the variable' port' could introduce bias if not correctly adjusted for operational variability. Hao and Ho's (2019) exposition on machine learning tools like sci-kit-learn further elucidates the necessity of selecting predictors that enhance a model's utility and interpretability, advocating for a rigorous and actionable methodology in analytics.

### [Data Transformation Project](https://github.com/aadegoke74/Data-Transformation-Project/blob/main/Section%204%20Data%20Transformation%20Project.ipynb)
- Proficient in executing data transformation projects, adept at manipulating and converting data across various formats and structures to meet project requirements. Experienced in utilizing advanced data transformation techniques and tools to cleanse, normalize, and integrate data from diverse sources. Skilled in developing and implementing efficient data transformation pipelines, ensuring transformed data accuracy, consistency, and reliability.
- Familiar with industry-standard data transformation methodologies and best practices, capable of optimizing data workflows and automating transformation processes for enhanced productivity and efficiency. Strong analytical and problem-solving abilities combined with meticulous attention to detail in managing data transformation projects effectively.
  
### [Bivariate Data Exploration Tasks](https://github.com/aadegoke74/Bivariate-Data-Exploration-Project/blob/main/Bivariate%20Data%20Exploration%20Project.ipynb)
- Statistics and distribution of the numerical time against one of the categorical variables
- An initial exploratory analysis is necessary to analyse how categorical variables affect the numerical "time" variable, which represents ship processing time. This includes computing average times per category and performing statistical tests to determine if variations in means are significant. Key categorical variables such as "weather," "onSchedule," "labour," "origin," "delay," and "port" are considered for their potential impact on processing time.
- Summary statistics and visual tools like boxplots will be used to discern disparities in processing time across different categories, indicating if deeper statistical evaluation is justified. The process involves calculating the mean, median, and standard deviation of "time" for each categorical variable and creating boxplots to observe distributions, outliers, and notable differences.

### [Data Exploration Tasks - Statistics of individual variables](https://github.com/aadegoke74/Data-Exploration-Project/blob/main/Data%20Exploration%20Tasks%20-%20Statistics%20of%20individual%20variables.ipynb) 
- Skilled in performing data exploration tasks, including statistical analysis of individual variables. Proficient in extracting insights and trends from data through thorough examination of variable distributions and descriptive statistics.

### [Data Cleaning](https://github.com/aadegoke74/Data-Cleaning-Project/blob/main/Data%20Cleaning%20Tasks.ipynb) 
- Load the data from the CSV file into a pandas DataFrame. Examine the data to identify which columns are numerical and which are categorical. For numerical columns: Calculate the mean of the column. Replace missing values with the mean of that column. For categorical columns: Determine the mode (most common value) of the column. Replace missing values with the mode of that column.
## References
- Available on Request
